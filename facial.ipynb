{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "d={}\n",
    "with open(\"data/legend.csv\") as file_obj:\n",
    "    file_data = csv.reader(file_obj)\n",
    "    next(file_data)\n",
    "    for row in file_data:\n",
    "        key=row[2].lower()\n",
    "        if key in d:\n",
    "            d[key].append(row[1])\n",
    "        else:\n",
    "            d[key]=[row[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger',\n",
       " 'surprise',\n",
       " 'disgust',\n",
       " 'fear',\n",
       " 'neutral',\n",
       " 'happiness',\n",
       " 'sadness',\n",
       " 'contempt']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_list = list(d.keys())\n",
    "emotion_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir(\"Masterdir\")\n",
    "os.mkdir(\"Masterdir/Training\")\n",
    "os.mkdir(\"Masterdir/Testing\")\n",
    "\n",
    "for each in emotion_list:\n",
    "    os.mkdir(os.path.join(\"Masterdir/Training/\",each))\n",
    "    os.mkdir(os.path.join(\"Masterdir/Testing/\",each))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "split_size = 0.8\n",
    "\n",
    "for emotion, images in d.items():\n",
    "  train_size = int(split_size*len(images))\n",
    "  train_images = images[:train_size]\n",
    "  test_images = images[train_size:]\n",
    "  for image in train_images:\n",
    "    source = os.path.join('images/', image)\n",
    "    dest = os.path.join('Masterdir/Training/', emotion, image)\n",
    "    copyfile(source, dest)\n",
    "  for image in test_images:\n",
    "    source = os.path.join('images/', image)\n",
    "    dest = os.path.join('Masterdir/Testing/', emotion, image)\n",
    "    copyfile(source, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 98, 98, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 49, 49, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 47, 47, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 23, 23, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 21, 21, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 10, 10, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              6554624   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 8200      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,586,408\n",
      "Trainable params: 6,586,408\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    Conv2D(16,(3,3),activation=\"relu\", input_shape=(100,100,3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(32,(3,3),activation=\"relu\"),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64,(3,3),activation=\"relu\"),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(1024,activation=\"relu\"),\n",
    "    Dense(8,activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=Adam(lr=0.01),loss=\"categorical_crossentropy\",metrics=[\"acc\"])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13683 images belonging to 8 classes.\n",
      "Found 2742 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "training_dir = \"Masterdir/Training\"\n",
    "testing_dir = \"Masterdir/Testing\"\n",
    "\n",
    "train_datagen=ImageDataGenerator(rescale=0.1/255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    training_dir,\n",
    "    target_size=(100,100),\n",
    "    class_mode = \"categorical\",\n",
    "    batch_size=128\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=0.1/255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    testing_dir,\n",
    "    target_size = (100,100),\n",
    "    class_mode= \"categorical\",\n",
    "    batch_size = 128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_acc', patience = 2, min_delta=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\visha\\AppData\\Local\\Temp\\ipykernel_13744\\687556935.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train_generator,epochs=10,verbose=1,validation_data=train_generator,callbacks=[es])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "107/107 [==============================] - 123s 1s/step - loss: 1.0191 - acc: 0.5435 - val_loss: 0.8440 - val_acc: 0.6922\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 69s 647ms/step - loss: 0.7405 - acc: 0.7373 - val_loss: 0.6770 - val_acc: 0.7666\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 69s 647ms/step - loss: 0.6293 - acc: 0.7821 - val_loss: 0.5856 - val_acc: 0.7948\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 71s 661ms/step - loss: 0.5849 - acc: 0.7976 - val_loss: 0.5338 - val_acc: 0.8164\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 69s 650ms/step - loss: 0.5303 - acc: 0.8163 - val_loss: 0.5018 - val_acc: 0.8262\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 69s 646ms/step - loss: 0.4970 - acc: 0.8261 - val_loss: 0.4658 - val_acc: 0.8414\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 69s 646ms/step - loss: 0.4641 - acc: 0.8371 - val_loss: 0.4469 - val_acc: 0.8451\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 68s 637ms/step - loss: 0.4392 - acc: 0.8470 - val_loss: 0.4437 - val_acc: 0.8413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fe273d7750>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator,epochs=10,verbose=1,validation_data=train_generator,callbacks=[es])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
